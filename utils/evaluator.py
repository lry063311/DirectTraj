import torch
import numpy as np
import time
from scipy.stats import entropy
from haversine import haversine
from tqdm import tqdm
from einops import rearrange


class TrajEvaluator:
    def __init__(self, config, global_stats, device):
        """
        [ç»ˆæé€šç”¨ç‰ˆè¯„ä¼°å™¨] - v4.0
        1. å…¼å®¹æ€§: æ™ºèƒ½è¯†åˆ« DataLoader è¿”å›é•¿åº¦ (2æˆ–3)ï¼Œæ”¯æŒ DiffTraj, ControlTraj, Traj-Transformer
        2. ä¿®å¤: é’ˆå¯¹ Porto ç­‰çŸ­è½¨è¿¹æ•°æ®é›†ï¼Œå†…ç½® Mask æœºåˆ¶å‰”é™¤å°¾éƒ¨å™ªå£°
        3. é²æ£’æ€§: ç‰©ç†æˆªæ–­é˜²æ­¢åæ ‡æº¢å‡ºï¼Œè‡ªé€‚åº”è®¡ç®—æˆªæ–­é˜ˆå€¼
        """
        self.cfg = config
        self.stats = global_stats
        self.device = device

        # ç¼“å­˜ GT æ•°æ®
        self.gt_trajs = None
        self.fixed_bounds = None
        self.gt_density_hist = None
        self.gt_trip_hist = None
        self.gt_len_hist = None

        # åŠ¨æ€æˆªæ–­å€¼
        self.dynamic_limit = 50.0

    def initialize(self, test_loader, road_processor=None):
        print("ğŸ“Š [Evaluator] åˆå§‹åŒ–ï¼šæ­£åœ¨åŠ è½½æµ‹è¯•é›†å¹¶è®¡ç®—å›ºå®šè¾¹ç•Œ...")
        self.road_processor = road_processor

        # 1. æ”¶é›†æ‰€æœ‰çœŸå®è½¨è¿¹ (GT)
        all_real = []
        for batch in test_loader:
            # ğŸ”¥ [å…¼å®¹æ€§ä¿®å¤] æ™ºèƒ½è§£åŒ…ï¼šä¸å†å¼ºåˆ¶è§£åŒ…ä¸º3ä¸ªå˜é‡
            # batch[0] å§‹ç»ˆæ˜¯è½¨è¿¹ x0
            x0 = batch[0].to(self.device)

            real_denorm = self._denormalize(x0)
            all_real.append(real_denorm.cpu().numpy().transpose(0, 2, 1))

        self.gt_trajs = np.concatenate(all_real, axis=0)

        # 2. è®¡ç®—å…¨åŸå›ºå®šè¾¹ç•Œ
        all_pts = self.gt_trajs.reshape(-1, 2)
        all_pts = all_pts[~np.isnan(all_pts).any(axis=1)]
        # è·å–æ•°æ®é›†åç§° (è½¬å°å†™)
        ds_name = str(self.cfg.Data.DATASET).lower()
        if 'porto_HIDDEN_SIZE = 64' in ds_name:
            # ğŸŸ¢ Porto æ¨¡å¼ï¼šæè‡´æ”¶ç´§ï¼Œä¸ºäº†è®© Density ä¸ä¸º 0
            print(f"   ğŸ¯ æ£€æµ‹åˆ° Porto æ•°æ®é›†ï¼šå¯ç”¨ Tight Mode (Padding=0, Percentile=0.5-99.5)")
            pct_range = [0.5, 99.5]
            padding = 0.0
        else:
            # ğŸ”µ SF / Beijing æ¨¡å¼ï¼šå®‰å…¨æ¨¡å¼ï¼Œé˜²æ­¢åˆ‡æ‰è¾¹ç¼˜çƒ­ç‚¹ (æœºåœº/é«˜é€Ÿå£)
            print(f"   ğŸ›¡ï¸ æ£€æµ‹åˆ° {self.cfg.Data.DATASET} æ•°æ®é›†ï¼šå¯ç”¨ Safe Mode (Padding=0.02, Percentile=0-100)")
            # æ¢å¤åˆ°å…¨èŒƒå›´ï¼Œé˜²æ­¢ SF çš„è¾¹ç¼˜ç‚¹è¢«åˆ‡
            pct_range = [0.1, 99.9]
            padding = 0.02
        lon_min, lon_max = np.percentile(all_pts[:, 0], pct_range)
        lat_min, lat_max = np.percentile(all_pts[:, 1], pct_range)
        self.fixed_bounds = {
            "lon_bound": [lon_min - padding, lon_max + padding],
            "lat_bound": [lat_min - padding, max(lat_max, lat_min + 0.01) + padding]
        }
        print(f"   âœ… è¾¹ç•Œå·²é”å®š: {self.fixed_bounds}")

        # 3. ğŸ”¥ [Mask å¢å¼º] è®¡ç®— GT é•¿åº¦åˆ†å¸ƒ
        # æ³¨æ„ï¼šè¿™é‡Œå¼€å¯ use_mask=Trueï¼Œç¡®ä¿ GT é‡Œçš„ 0-padding è¢«æ­£ç¡®å¿½ç•¥
        raw_lens = self._get_len_raw_values(self.gt_trajs, use_mask=True)
        p99 = np.percentile(raw_lens, 99)
        self.dynamic_limit = np.ceil(p99 / 10) * 10
        print(f"   ğŸ“ [AutoTune] GT 99% é•¿åº¦: {p99:.2f} km")
        print(f"   âš™ï¸ [AutoTune] è‡ªåŠ¨è®¾å®šè¯„ä¼°æˆªæ–­å€¼ (Clip Limit): {self.dynamic_limit} km")

        # 4. é¢„è®¡ç®— GT ç›´æ–¹å›¾
        self.gt_density_hist = self._to_grid(self.gt_trajs, self.fixed_bounds)
        # Trip Error å–èµ·ç‚¹å’Œç»ˆç‚¹ (Mask é€»è¾‘ä¿è¯äº†ç»ˆç‚¹çš„æœ‰æ•ˆæ€§)
        gt_trip_pts = np.stack([self.gt_trajs[:, 0, :], self.gt_trajs[:, -1, :]], axis=1)
        self.gt_trip_hist = self._to_grid(gt_trip_pts, self.fixed_bounds)
        self.gt_len_hist = self._get_len_dist(self.gt_trajs, use_mask=True)
        print("   âœ… GT åˆ†å¸ƒè®¡ç®—å®Œæ¯•")

    # ================= æ ¸å¿ƒå·¥å…·å‡½æ•° =================

    def _denormalize(self, x):
        """åå½’ä¸€åŒ– + ç‰©ç†æˆªæ–­ (é˜²æ­¢ NaN)"""
        x = x.clone().detach()
        x = torch.nan_to_num(x, nan=0.0, posinf=5.0, neginf=-5.0)
        x[:, 0, :] = x[:, 0, :] * self.stats["lon_std"] + self.stats["lon_mean"]
        x[:, 1, :] = x[:, 1, :] * self.stats["lat_std"] + self.stats["lat_mean"]

        # ğŸ”¥ ç‰©ç†å¼ºçº¦æŸï¼šé˜²æ­¢åæ ‡é£å‡ºåœ°çƒå¯¼è‡´ Haversine å´©æºƒ
        x[:, 0, :] = torch.clamp(x[:, 0, :], -180.0, 180.0)
        x[:, 1, :] = torch.clamp(x[:, 1, :], -90.0, 90.0)
        return x

    def _get_valid_length_mask(self, trajs):
        """
        ğŸ”¥ [æ ¸å¿ƒç®—æ³•] æ™ºèƒ½å»å™ª Mask
        è‡ªåŠ¨æ£€æµ‹è½¨è¿¹æœ«ç«¯çš„é™æ­¢åŒºåŸŸ (Padding å™ªå£°)ï¼Œè¿”å›æœ‰æ•ˆé•¿åº¦çš„å¸ƒå°”æ©ç ã€‚
        é€‚ç”¨äºï¼šPorto (çŸ­è½¨è¿¹å»å™ª) å’Œ Beijing/SF (å°¾éƒ¨å»å™ª)ã€‚
        """
        masks = []
        for t in trajs:
            # è®¡ç®—æ¯ä¸€æ­¥çš„ä½ç§»
            diffs = np.linalg.norm(t[1:] - t[:-1], axis=1)

            is_moving = diffs > 1e-6

            # ä»åå¾€å‰æ‰«æï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªâ€œåŠ¨â€çš„ç‚¹ï¼Œå³ä¸ºæœ‰æ•ˆç»ˆç‚¹
            valid_len = len(t)
            for i in range(len(t) - 2, 0, -1):
                if is_moving[i]:
                    valid_len = i + 2
                    break

            # æ„å»º mask
            m = np.zeros(len(t), dtype=bool)
            m[:valid_len] = True
            masks.append(m)
        return masks

    def _get_len_raw_values(self, trajs, use_mask=True):
        """è®¡ç®—è½¨è¿¹é•¿åº¦ (æ”¯æŒ Mask)"""
        vals = []
        is_beijing = 'beijing' in str(self.cfg.Data.DATASET).lower()

        # è·å–æ©ç 
        if use_mask:
            masks = self._get_valid_length_mask(trajs)
        else:
            masks = [np.ones(len(t), dtype=bool) for t in trajs]

        for i, t in enumerate(trajs):
            # ğŸ”¥ åº”ç”¨ Maskï¼šåªå–æœ‰æ•ˆç‚¹è®¡ç®—è·ç¦»
            valid_t = t[masks[i]]

            if len(valid_t) < 2:
                vals.append(0.0)
                continue

            d = 0.0
            for k in range(len(valid_t) - 1):
                step = haversine((valid_t[k, 1], valid_t[k, 0]),
                                 (valid_t[k + 1, 1], valid_t[k + 1, 0]))
                if is_beijing:
                    d += step
                else:
                    # Porto å®¹é”™ï¼šè·³è·ƒè¿‡å¤§ (>1km) è§†ä¸ºå¼‚å¸¸
                    if step <= 1.0: d += step
            vals.append(d)
        return vals

    def _get_len_dist(self, trajs, use_mask=True):
        """è·å–é•¿åº¦åˆ†å¸ƒç›´æ–¹å›¾"""
        raw_lens = self._get_len_raw_values(trajs, use_mask=use_mask)
        clipped = np.clip(raw_lens, 0.0, self.dynamic_limit)
        hist, _ = np.histogram(clipped, bins=np.linspace(0, self.dynamic_limit, 51))
        return hist.astype(float) / (hist.sum() + 1e-10)

    def _to_grid(self, trajs, bounds, grid_num=16):
        """æ˜ å°„åˆ°ç½‘æ ¼çƒ­åŠ›å›¾ (é€šç”¨)"""
        lon_min, lon_max = bounds["lon_bound"]
        lat_min, lat_max = bounds["lat_bound"]
        grid = np.zeros((grid_num, grid_num))

        if trajs.ndim == 3:
            all_pts = np.concatenate(trajs, axis=0)
        else:
            all_pts = trajs

        # ç®€å•çš„ NaN è¿‡æ»¤
        all_pts = all_pts[~np.isnan(all_pts).any(axis=1)]

        mask = (all_pts[:, 0] >= lon_min) & (all_pts[:, 0] <= lon_max) & \
               (all_pts[:, 1] >= lat_min) & (all_pts[:, 1] <= lat_max)
        valid = all_pts[mask]

        c = ((valid[:, 0] - lon_min) / (lon_max - lon_min) * grid_num).astype(int)
        r = ((valid[:, 1] - lat_min) / (lat_max - lat_min) * grid_num).astype(int)

        np.add.at(grid, (np.clip(r, 0, grid_num - 1), np.clip(c, 0, grid_num - 1)), 1)
        return grid.flatten() / (grid.sum() + 1e-10)

    def _js_divergence(self, p, q):
        m = 0.5 * (p + q)
        return 0.5 * (entropy(p, m) + entropy(q, m))

    # ================= å…¬å¼€è°ƒç”¨æ¥å£ =================
    @torch.no_grad()
    def evaluate(self, model, road_encoder, test_loader, sampling_func):
        model.eval()
        if road_encoder is not None:
            road_encoder.eval()

        gen_trajs = []

        # ==========================================
        # 1. ç‹¬ç«‹æµ‹é€Ÿé€»è¾‘ (å¼ºåˆ¶ BS=1)
        # ==========================================
        print("â±ï¸  [Evaluator] æ­£åœ¨æ‰§è¡Œå•æ¡æ¨ç†æµ‹é€Ÿ (BS=1)...")

        # ğŸ”¥ [å…¼å®¹æ€§] å®‰å…¨è·å–å•æ¡æ•°æ®
        dummy_batch = next(iter(test_loader))
        x0_single = dummy_batch[0][0:1].to(self.device)
        attr_single = dummy_batch[1][0:1].to(self.device)
        # æ™ºèƒ½åˆ¤æ–­ batch æ˜¯å¦åŒ…å« road (DiffTraj=No, ControlTraj=Yes)
        road_single = dummy_batch[2][0:1].to(self.device) if len(dummy_batch) > 2 else None

        # ğŸ”¥ [å…¼å®¹æ€§] è‡ªåŠ¨æ„é€  r_emb
        r_emb_single = None
        if road_encoder is not None and road_single is not None:
            # æ¨¡å¼ A: ControlTraj (æœ‰ Encoder + æœ‰æ•°æ®)
            r_in = self.road_processor.prepare_road_mae_input(road_single)
            r_emb_single = self.road_processor.extract_road_features(road_encoder, r_in, no_mask=True)
        elif hasattr(model, 'config') and hasattr(model.config, 'model'):
            # æ¨¡å¼ B: DiffTraj (æ—  Encoder, éœ€è¦å ä½ç¬¦)
            r_emb_single = torch.zeros((1, 1, model.config.model.ch)).to(self.device)

        x_noise_single = torch.randn_like(x0_single)

        # é¢„çƒ­
        for _ in range(5):
            _ = sampling_func(model, x_noise_single, r_emb_single, attr_single)

        # æµ‹é€Ÿ
        start_event = torch.cuda.Event(enable_timing=True)
        end_event = torch.cuda.Event(enable_timing=True)
        latencies = []

        for _ in range(50):
            torch.cuda.synchronize()
            start_event.record()
            _ = sampling_func(model, x_noise_single, r_emb_single, attr_single)
            end_event.record()
            torch.cuda.synchronize()
            latencies.append(start_event.elapsed_time(end_event))

        avg_latency = np.mean(latencies)
        print(f"â±ï¸  å•æ¡æ¨ç†å»¶è¿Ÿ (Real-time Latency): {avg_latency:.4f} ms")

        # ==========================================
        # 2. å…¨é‡ç”Ÿæˆé€»è¾‘
        # ==========================================
        print("ğŸš€ [Evaluator] æ­£åœ¨ç”Ÿæˆå…¨é‡æµ‹è¯•é›† (Auto-Masking Enabled)...")

        for batch in tqdm(test_loader, desc="Generating"):
            # ğŸ”¥ [å…¼å®¹æ€§] æ™ºèƒ½è§£åŒ…
            x0_real = batch[0].to(self.device)
            attr = batch[1].to(self.device)
            # æ™ºèƒ½åˆ¤æ–­
            road = batch[2].to(self.device) if len(batch) > 2 else None

            # ğŸ”¥ [å…¼å®¹æ€§] è‡ªåŠ¨æ„é€  r_emb
            r_emb = None
            if road_encoder is not None and road is not None:
                # æ¨¡å¼ A: æœ‰è·¯ç½‘çº¦æŸ
                r_in = self.road_processor.prepare_road_mae_input(road)
                r_emb = self.road_processor.extract_road_features(road_encoder, r_in, no_mask=True)
            elif hasattr(model, 'config') and hasattr(model.config, 'model'):
                # æ¨¡å¼ B: æ— è·¯ç½‘çº¦æŸ (ç”Ÿæˆ DiffTraj æ‰€éœ€ç»´åº¦çš„é›¶å‘é‡)
                r_emb = torch.zeros((len(x0_real), 1, model.config.model.ch)).to(self.device)

            x_noise = torch.randn_like(x0_real)

            # ç”Ÿæˆ
            x_gen = sampling_func(model, x_noise, r_emb, attr)

            # åå½’ä¸€åŒ–
            gen_np = self._denormalize(x_gen).cpu().numpy().transpose(0, 2, 1)

            # âš ï¸ æ³¨æ„ï¼šè¿™é‡Œä¸å†è¿›è¡Œ "Uniform Redistribute"ï¼Œå› ä¸ºé‚£ä¼šç ´åå°¾éƒ¨é™æ­¢ç‰¹å¾
            # ç›´æ¥ä¿å­˜åŸå§‹ç‚¹ï¼Œè®©åé¢çš„ Mask é€»è¾‘å»å¤„ç†
            gen_trajs.append(gen_np)

        gen_all = np.concatenate(gen_trajs, axis=0)

        # ==========================================
        # 3. è®¡ç®—æŒ‡æ ‡ (æ ¸å¿ƒ)
        # ==========================================
        print("ğŸ“Š [Evaluator] è®¡ç®—æŒ‡æ ‡ä¸­...")

        d_err = self._js_divergence(self.gt_density_hist, self._to_grid(gen_all, self.fixed_bounds))

        gen_trip_pts = np.stack([gen_all[:, 0, :], gen_all[:, -1, :]], axis=1)
        t_err = self._js_divergence(self.gt_trip_hist, self._to_grid(gen_trip_pts, self.fixed_bounds))

        # ğŸ”¥ Length Error: é‡ç‚¹ï¼è¿™é‡Œä¼šè‡ªåŠ¨è°ƒç”¨ Mask é€»è¾‘å‰”é™¤å™ªå£°
        l_err = self._js_divergence(self.gt_len_hist, self._get_len_dist(gen_all, use_mask=True))

        # è¯Šæ–­ä¿¡æ¯
        real_len_raw = self._get_len_raw_values(self.gt_trajs, use_mask=True)
        gen_len_raw = self._get_len_raw_values(gen_all, use_mask=True)

        print("\n" + "=" * 40)
        print("ğŸ•µï¸â€â™‚ï¸ [DEBUG] ç»“æœæ¦‚è§ˆ:")
        print(f"   â±ï¸ Latency: {avg_latency:.2f} ms")
        print(f"   ğŸ“ Length Error: {l_err:.4f}")
        print(f"   ğŸ¤– Gen Avg Length: {np.mean(gen_len_raw):.4f} km (GT: {np.mean(real_len_raw):.4f})")
        print("=" * 40 + "\n")

        # ğŸ¤– æ™ºèƒ½æ¨æ–­ï¼šæ ¹æ®ç»åº¦å‡å€¼åˆ¤æ–­åŸå¸‚
        # Evaluator å¿…å®šæœ‰ self.stats ç”¨äºåå½’ä¸€åŒ–ï¼Œåˆ©ç”¨å®ƒï¼
        lon_mean = self.stats['lon_mean']

        if lon_mean > 100:  # åŒ—äº¬ç»åº¦çº¦ 116
            dataset_name = "beijing"
        elif lon_mean < -100:  # æ—§é‡‘å±±ç»åº¦çº¦ -122
            dataset_name = "sf"
        else:  # æ³¢å°”å›¾ç»åº¦çº¦ -8
            dataset_name = "porto_HIDDEN_SIZE = 64"

        print(f"ğŸŒ [Auto-Detect] æ£€æµ‹åˆ°æ•°æ®é›†: {dataset_name} (Lon: {lon_mean:.1f})")

        # ä¿å­˜æ–‡ä»¶
        save_name_ours = f"{dataset_name}_ours.npy"
        save_name_gt = f"{dataset_name}_gt.npy"
        np.save(save_name_ours, np.array(gen_len_raw))
        np.save(save_name_gt, np.array(real_len_raw))

        print(f"ğŸ’¾ [Auto-Save] DirectTraj (Ours) Saved: {save_name_ours}")
        print(f"ğŸ’¾ [Auto-Save] Ground Truth Saved: {save_name_gt}")

        return {
            "Density Error": d_err,
            "Trip Error": t_err,
            "Length Error": l_err,
            "Latency (ms)": avg_latency
        }